# Methods and Materials

##  Data Collection
Our data collection was primarily conducted at Kentland Farm, Virginia Tech. Utilizing two Amazon Ring cameras, we adopted a dual-view approach: one camera was set up for top views while the other was aimed for side views. Our collection comprised approximately N videos (the exact number to be inserted), with our sampling strategy designed to extract one frame every second. Recognizing the crucial role of lighting in data quality, we strategically gathered data during various times of the day: morning, noon, evening, and night. This helped ensure diversity and richness in our dataset. In the span of our data collection, the farm, which houses over 200 cows of both Jersey and Holstein breeds, served as an apt setting for comprehensive data representation.

## Data Preparation
For the purpose of labeling our dataset, we employed Roboflow, a platform that facilitated the bounding box annotations. Roboflow was particularly beneficial as it allowed us to obtain our data in two prominent formats: COCO and YOLOv5. As for the images extracted, they were consistently saved in the JPG format, ensuring uniformity in our data representation.


(last, year)

## Model architecture

### YOLO-family

### DETR

#### ResNet backbone

#### Attention mechanism

### Mask-R-CNN

