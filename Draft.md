# Detecting objects in animal and dairy sciences using machine learning models.


## Introduction

Object deteciton, which tracks the positions of interested objects (e.g., cows and sheeps), has been an essential tool to improve the livestock production. For instance a recent study introduced a method to accurately classify the posture of pigs based on images. They used YOLOv5, which achieved a pig detection accuracy of 0.994 with an APIoU=0.5. Then they utilized EfficientNet to classify the detected pigs into 'lying' and 'notLying' postures achieving a precision rate of 0.93. This innovative approach demonstrated the advantages of using models, for classifying pig posture resulting in improvements, in accuracy. These studies have addressed the issue that researchers aimed to solve.[Jan-Hendrik Witte,Jorge Marx Gom ÃÅez, 2022 ]. Another study, in the field of precision livestock farming has introduced an cost effective approach to identify beef cattle and monitor their activities using surveillance camera. This method utilizes real time object detection YOLOv3 to focus on the areas of the cattle and accurately locate ear tags. It also detects water consumption behaviors near drinking areas. By incorporating an Optical Character Recognition (OCR) algorithm the system is able to read cow IDs with accuracy achieving an impressive detection rate of 89% at mAP@0.50[Andrea Pretto a,*, Gianpaolo Savio a, Flaviana Gottardo b, Francesca Uccheddu c, Gianmaria Concheri a, 2022]. These studies have alleivate the problem that researchers want to solve.

However, the costs, including labor, time, and computational resources, to implement the object detection were rarely addressed. For example, researchers conducted a study, on precision dairy farming, in Hokkaido, Japan. They successfully developed a system that could recognize cows ear tags using the object detector. To achieve this they needed a dataset of 20,000 training samples that were specifically focused on detecting cow heads.[Thi Thi Zin, Shuhei Misawa, Moe Zet Pwint, Kosuke Sumi, Kyohiro Yoshida, 2020]. Preparing this amount of samples can be labor-intesntive, as formatting and labeling the positions of each object in an image requires professional training in programming language. For example, COCO annotation format is the most common format for object detection. It requires organizing the coordinates of the bounding box, the class of the object, and the image size in a JSON file. Without related expertise, there is a barrier to implement object detection in animal and dairy sciences. Another obstacle of the implementation is the computational resources. Not every computer can implement the modern object detection models, which have millions of parameters and requires up to 12 GB of video memory. For instance, the VGG-16 model has 138 million parameters and recommends a VRAM of at least 8GB, while the ResNet-152 has around 60 million parameters with a recommended VRAM of 11GB. Hence, knowing the computational cost is also an important factor for researchers to consider when implementing object detection. Lastly, the transferability of the published studies is always missed to be discussed. This factor is important when one research want to reproduce the same published work in their own research, which may have different lighting or environment that affects the model performance. Transfering the model to a new environment usually reuqires providing additional training efforts, which is also a cost to consider.

To date, most object detection studies in animal sciences did not address the listed concerns.
<TO BE FILLED>
    - Dr. Dorea's study (2-3 sentences)
    - YOLO models / Mask RCNN in animal science
    - Transformer is great but rare, list two work outside of animal science

In this study, we present a systematic benchmarking study that addresses the concerns and provides a guidence for researchers, regardless of their expertise, to implement object detection in livestock production studies. Specifically, we aims to discuss three major perspectives of the implementation:
- (1) How many training samples are required to achieve a certain accuracy?
- (2) How much computational resources are required to implement the object detection?
- (3) How much marginal efforts (i.e., samples) are required to transfer the model to a new environment?
We will validate each goal by using state of the art object detection models, including YOLOv8, YOLONAS, Mask R-CNN, and transformer-based model DETR, with their variants that have different model sizes. For benchmarking the performance in tranferability, we collected image datasets of dairy cows and ensured the variation of the lighting environment (i.e., day and night), camera angles (i.e., top-down and side-view), and even the breeds (i.e., Holstein and Jersey). We will also discuss the trade-off between the accuracy and the computational resources. With this guidence, researchers who want to implemenet the object detection can have better management of their research resources and efforts.

## Methods and Materials

(last, year)

