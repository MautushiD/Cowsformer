{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mautushid/Cowsformer\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(\"..\")\n",
    "ROOT = os.getcwd()\n",
    "print(ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib created a temporary cache directory at /localscratch/2210632/matplotlib-57s68ata because the default path (/home/jovyan/.cache/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The console stream is logged into /home/mautushid/sg_logs/console.log\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-03-14 16:05:35] INFO - crash_tips_setup.py - Crash tips is enabled. You can set your environment variable to CRASH_HANDLER=FALSE to disable it\n",
      "[2024-03-14 16:05:36] WARNING - __init__.py - Failed to import pytorch_quantization\n",
      "[2024-03-14 16:05:43] WARNING - calibrator.py - Failed to import pytorch_quantization\n",
      "[2024-03-14 16:05:43] WARNING - export.py - Failed to import pytorch_quantization\n",
      "[2024-03-14 16:05:43] WARNING - selective_quantization_utils.py - Failed to import pytorch_quantization\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import NAS\n",
    "import logging\n",
    "import supervision as sv\n",
    "from API import*\n",
    "from evaluate import from_sv\n",
    "import warnings\n",
    "from models.nas import *\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ['TORCH_HOME'] = '/home/mautushid/.torch'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# local imports\n",
    "from iou_utils_NAS import *\n",
    "from models.nas import Niche_YOLO_NAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### class inits and other inputs\n",
    "\n",
    "path_model = 'yolo_nas_l' \n",
    "dir_train = \"/home/mautushid/Cowsformer/data/1a_angle_t2s/tv/exp_yolo_nas_l_16_1_t2s_yolo_nas_l_16_1/train\"\n",
    "dir_val = \"/home/mautushid/Cowsformer/data/1a_angle_t2s/tv/exp_yolo_nas_l_16_1_t2s_yolo_nas_l_16_1/val\"\n",
    "dir_test = \"/home/mautushid/Cowsformer/data/1a_angle_t2s/test\"\n",
    "name_task = \"cow200\"\n",
    "\n",
    "data_yaml_path = \"/home/mautushid/Cowsformer/data/1a_angle_t2s/tv/data.yaml\"\n",
    "#finetuned_model_path = \"/home/mautushid/Cowsformer/checkpoints/n256_yolo_nas_l_i2_all/RUN_20240301_070915_136444/ckpt_best.pth\"\n",
    "#finetuned_model_path = \"/home/mautushid/Cowsformer/checkpoints/n256_yolo_nas_l_i1_all/RUN_20240229_194610_358069/ckpt_best.pth\"\n",
    "### Creating instance of Niche_YOLO_NAS class\n",
    "my_nas = Niche_YOLO_NAS(path_model, dir_train, dir_val, dir_test, name_task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_nas.train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best_model = my_nas.load(path_model,finetuned_model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_nas.evaluate_trained_model(best_model, data_yaml_path, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### in one iteration 4_all map high , in other low checking each of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_label_path = \"/home/mautushid/Cowsformer/data/1a_angle_t2s/test/labels\"\n",
    "gt_img_path =  \"/home/mautushid/Cowsformer/data/1a_angle_t2s/test\"\n",
    "pred_label_path = \"/home/mautushid/Cowsformer/data/1a_angle_t2s/test/exp_yolo_nas_l_500_1_labelsPred\"\n",
    "api = YOLO_API(\"/home/mautushid/Cowsformer/data/1a_angle_t2s/tv/exp_yolo_nas_l_500_1_t2s_yolo_nas_l_500_1\") \n",
    "lbs = api.get_gt_detections(gt_label_path, gt_img_path)\n",
    "pre = api.get_pred_detections(pred_label_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "op = from_sv(pre, lbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_label_path = \"/home/mautushid/Cowsformer/data/4_all/test/labels\"\n",
    "gt_img_path =  \"/home/mautushid/Cowsformer/data/4_all/test\"\n",
    "pred_label_path = \"/home/mautushid/Cowsformer/data/4_all/test/yolo_nas_l_256_2_labelsPred\"\n",
    "api = YOLO_API(\"/home/mautushid/Cowsformer/data/4_all/tv/exp_yolo_nas_l_256_2_all_yolo_nas_l_256_2\") \n",
    "lbs = api.get_gt_detections(gt_label_path, gt_img_path)\n",
    "pre = api.get_pred_detections(pred_label_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "op1 = from_sv(pre, lbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "op1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_label_path = \"/home/mautushid/Cowsformer/data/4_all/test/labels\"\n",
    "gt_img_path =  \"/home/mautushid/Cowsformer/data/4_all/test\"\n",
    "pred_label_path = \"/home/mautushid/Cowsformer/data/4_all/test/yolo_nas_l_500_1_labelsPred\"\n",
    "api = YOLO_API(\"/home/mautushid/Cowsformer/data/4_all/tv/exp_yolo_nas_l_500_1_all_yolo_nas_l_500_1\") \n",
    "lbs = api.get_gt_detections(gt_label_path, gt_img_path)\n",
    "pre = api.get_pred_detections(pred_label_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "op2 = from_sv(pre, lbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "op2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_label_path = \"/home/mautushid/Cowsformer/data/4_all/test/labels\"\n",
    "gt_img_path =  \"/home/mautushid/Cowsformer/data/4_all/test\"\n",
    "pred_label_path = \"/home/mautushid/Cowsformer/data/4_all/test/yolo_nas_l_500_2_labelsPred\"\n",
    "api = YOLO_API(\"/home/mautushid/Cowsformer/data/4_all/tv/exp_yolo_nas_l_500_2_all_yolo_nas_l_500_2\") \n",
    "lbs = api.get_gt_detections(gt_label_path, gt_img_path)\n",
    "pre = api.get_pred_detections(pred_label_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "op3 = from_sv(pre, lbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "op3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 14/03/2024 ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found empty GT\n",
      "found empty GT\n",
      "found empty GT\n",
      "found empty GT\n",
      "found empty GT\n",
      "found empty GT\n",
      "found empty GT\n",
      "found empty GT\n",
      "found empty GT\n"
     ]
    }
   ],
   "source": [
    "gt_label_path = \"/home/mautushid/Cowsformer/data/4_all/test/labels\"\n",
    "gt_img_path =  \"/home/mautushid/Cowsformer/data/4_all/test\"\n",
    "pred_label_path = \"/home/mautushid/Cowsformer/data/4_all/test/exp_yolo_nas_s_500_9_labelsPred\"\n",
    "api = YOLO_API(\"/home/mautushid/Cowsformer/data/4_all/tv/exp_yolo_nas_s_500_9_all_yolo_nas_s_500_9\") \n",
    "#lbs = api.get_gt_detections(gt_label_path, gt_img_path)\n",
    "#pre = api.get_pred_detections(pred_label_path)\n",
    "#pre = api.get_gt_detections(pred_label_path,gt_img_path)\n",
    "\n",
    "obs,pre = api.get_gt_pred_detections(gt_img_path,gt_label_path,pred_label_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "op3 = from_sv(pre, obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'map5095': 0.6575896505073929,\n",
       " 'map50': 0.9315211164173515,\n",
       " 'precision': 0.8314321926489227,\n",
       " 'recall': 0.9174825174825175,\n",
       " 'f1': 0.8723404255319149,\n",
       " 'n_all': 2860,\n",
       " 'n_fn': 236,\n",
       " 'n_fp': 532}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "op3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Ground truth boxes\n",
    "    for box in prediction_dict[\"Ground_Truth_boxes\"]:\n",
    "        x_min, y_min, x_max, y_max = map(int, box)\n",
    "        cv2.rectangle(\n",
    "            image, (x_min, y_min), (x_max, y_max), (255, 0, 0), 1\n",
    "        )  # Red color\n",
    "\n",
    "    # Default model boxes\n",
    "    for box in prediction_dict[\"Default_YoloNas_boxes\"]:\n",
    "        x_min, y_min, x_max, y_max = map(int, box)\n",
    "        cv2.rectangle(\n",
    "            image, (x_min, y_min), (x_max, y_max), (0, 0, 255), 1\n",
    "        )  # Blue color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_boxes_gt_pred(image_dir,gt_label_dir,pred_label_dir):\n",
    "    \n",
    "def draw_boxes_gt(image_dir,gt_label_dir):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def draw_nboxes_gt(image_dir, gt_label_dir, n=5):\n",
    "    \"\"\"\n",
    "    This function reads images from an image directory and their corresponding GT label files from the gt_label_dir,\n",
    "    but processes only the first `n` images found. It draws bounding boxes on the images according to the GT labels.\n",
    "    \n",
    "    Parameters:\n",
    "    - image_dir: Path to the directory containing images.\n",
    "    - gt_label_dir: Path to the directory containing GT label files in YOLOv5 format.\n",
    "    - n: The number of images to process.\n",
    "    \"\"\"\n",
    "    images_processed = 0\n",
    "    for filename in sorted(os.listdir(image_dir)):\n",
    "        if images_processed >= n:\n",
    "            break\n",
    "        if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "            image_path = os.path.join(image_dir, filename)\n",
    "            label_path = os.path.join(gt_label_dir, os.path.splitext(filename)[0] + '.txt')\n",
    "            \n",
    "            if os.path.exists(label_path):\n",
    "                image = cv2.imread(image_path)\n",
    "                h, w, _ = image.shape\n",
    "                \n",
    "                with open(label_path, 'r') as f:\n",
    "                    lines = f.readlines()\n",
    "                \n",
    "                for line in lines:\n",
    "                    parts = line.strip().split()\n",
    "                    _, x_center, y_center, width, height = map(float, parts)\n",
    "                    \n",
    "                    x_center, y_center, width, height = x_center * w, y_center * h, width * w, height * h\n",
    "                    x_min = int(x_center - width / 2)\n",
    "                    y_min = int(y_center - height / 2)\n",
    "                    x_max = int(x_center + width / 2)\n",
    "                    y_max = int(y_center + height / 2)\n",
    "                    \n",
    "                    cv2.rectangle(image, (x_min, y_min), (x_max, y_max), (0, 0, 255), thickness=4)\n",
    "                \n",
    "                # Convert BGR image to RGB\n",
    "                image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "                plt.figure(figsize=(10, 10))\n",
    "                plt.imshow(image_rgb)\n",
    "                plt.title(f\"Image: {filename}\")\n",
    "                plt.axis('off')\n",
    "                plt.show()\n",
    "                \n",
    "                images_processed += 1\n",
    "\n",
    "def draw_nboxes_pred(image_dir, pred_label_dir, n=5):\n",
    "    \"\"\"\n",
    "    This function reads images from an image directory and their corresponding prediction label files from the pred_label_dir,\n",
    "    but processes only the first `n` images found. It draws bounding boxes on the images according to the prediction labels.\n",
    "    \n",
    "    Parameters:\n",
    "    - image_dir: Path to the directory containing images.\n",
    "    - pred_label_dir: Path to the directory containing prediction label files.\n",
    "    - n: The number of images to process.\n",
    "    \"\"\"\n",
    "    images_processed = 0\n",
    "    for filename in sorted(os.listdir(image_dir)):\n",
    "        if images_processed >= n:\n",
    "            break\n",
    "        if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "            image_path = os.path.join(image_dir, filename)\n",
    "            label_path = os.path.join(pred_label_dir, os.path.splitext(filename)[0] + '.txt')\n",
    "            \n",
    "            if os.path.exists(label_path):\n",
    "                image = cv2.imread(image_path)\n",
    "                \n",
    "                with open(label_path, 'r') as f:\n",
    "                    lines = f.readlines()\n",
    "                \n",
    "                for line in lines:\n",
    "                    parts = line.strip().split()\n",
    "                    # Adjust this part to match the prediction label format\n",
    "                    _, x_min, y_min, x_max, y_max, confidence = map(float, parts)\n",
    "                    \n",
    "                    # Convert coordinates to integers\n",
    "                    x_min, y_min, x_max, y_max = map(int, [x_min, y_min, x_max, y_max])\n",
    "                    \n",
    "                    # Draw rectangle using the top-left and bottom-right coordinates\n",
    "                    cv2.rectangle(image, (x_min, y_min), (x_max, y_max), (0, 255, 0), thickness=2)\n",
    "                    # Optional: Display the confidence score\n",
    "                    cv2.putText(image, f\"{confidence:.2f}\", (x_min, y_min-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "                \n",
    "                # Convert BGR image to RGB\n",
    "                image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "                plt.figure(figsize=(10, 10))\n",
    "                plt.imshow(image_rgb)\n",
    "                plt.title(f\"Image: {filename} with Predictions\")\n",
    "                plt.axis('off')\n",
    "                plt.show()\n",
    "                \n",
    "                images_processed += 1\n",
    "def draw_nboxes_gt_pred(image_dir, gt_label_dir, pred_label_dir, n=5):\n",
    "    \"\"\"\n",
    "    This function reads images from an image directory and their corresponding GT label files and prediction label files,\n",
    "    drawing bounding boxes on the images according to both GT labels and prediction labels, for only the first `n` images found.\n",
    "    \n",
    "    Parameters:\n",
    "    - image_dir: Path to the directory containing images.\n",
    "    - gt_label_dir: Path to the directory containing GT label files in YOLOv5 format.\n",
    "    - pred_label_dir: Path to the directory containing prediction label files.\n",
    "    - n: The number of images to process.\n",
    "    \"\"\"\n",
    "    images_processed = 0\n",
    "    for filename in sorted(os.listdir(image_dir)):\n",
    "        if images_processed >= n:\n",
    "            break\n",
    "        if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "            image_path = os.path.join(image_dir, filename)\n",
    "            gt_label_path = os.path.join(gt_label_dir, os.path.splitext(filename)[0] + '.txt')\n",
    "            pred_label_path = os.path.join(pred_label_dir, os.path.splitext(filename)[0] + '.txt')\n",
    "            \n",
    "            image = cv2.imread(image_path)\n",
    "            h, w, _ = image.shape\n",
    "            \n",
    "            # Draw GT boxes\n",
    "            if os.path.exists(gt_label_path):\n",
    "                with open(gt_label_path, 'r') as f:\n",
    "                    lines = f.readlines()\n",
    "                \n",
    "                for line in lines:\n",
    "                    parts = line.strip().split()\n",
    "                    _, x_center, y_center, width, height = map(float, parts)\n",
    "                    \n",
    "                    x_center, y_center, width, height = x_center * w, y_center * h, width * w, height * h\n",
    "                    x_min = int(x_center - width / 2)\n",
    "                    y_min = int(y_center - height / 2)\n",
    "                    x_max = int(x_center + width / 2)\n",
    "                    y_max = int(y_center + height / 2)\n",
    "                    \n",
    "                    cv2.rectangle(image, (x_min, y_min), (x_max, y_max), (0, 0, 255), thickness=4)\n",
    "            \n",
    "            # Draw prediction boxes\n",
    "            if os.path.exists(pred_label_path):\n",
    "                with open(pred_label_path, 'r') as f:\n",
    "                    lines = f.readlines()\n",
    "                \n",
    "                for line in lines:\n",
    "                    parts = line.strip().split()\n",
    "                    _, x_min, y_min, x_max, y_max, confidence = map(float, parts)\n",
    "                    \n",
    "                    x_min, y_min, x_max, y_max = map(int, [x_min, y_min, x_max, y_max])\n",
    "                    \n",
    "                    cv2.rectangle(image, (x_min, y_min), (x_max, y_max), (0, 255, 0), thickness=2)\n",
    "                    cv2.putText(image, f\"{confidence:.2f}\", (x_min, y_min-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "            \n",
    "            # Convert BGR image to RGB and display\n",
    "            image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            plt.figure(figsize=(10, 10))\n",
    "            plt.imshow(image_rgb)\n",
    "            plt.title(f\"Image: {filename} - GT and Predictions\")\n",
    "            plt.axis('off')\n",
    "            plt.show()\n",
    "            \n",
    "            images_processed += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_label_dir = \"/home/mautushid/Cowsformer/data/4_all/test/labels\"\n",
    "gt_img_dir =  \"/home/mautushid/Cowsformer/data/4_all/test/images\"\n",
    "pred_label_dir = \"/home/mautushid/Cowsformer/data/4_all/test/exp_yolo_nas_l_500_2_labelsPred\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "draw_nboxes_gt_pred(gt_img_dir, gt_label_dir, pred_label_dir, n=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[2,4,6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from_sv0(preds, obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = api.get_gt_detections(gt_label_path, gt_img_path)\n",
    "preds = api.get_pred_detections(pred_label_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_metrics(obs, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_total_bboxes(gt_label_dir):\n",
    "    \"\"\"\n",
    "    This function reads GT label files from the gt_label_dir and counts the total number of bounding boxes\n",
    "    across all label files.\n",
    "    \n",
    "    Parameters:\n",
    "    - gt_label_dir: Path to the directory containing GT label files in YOLOv5 format.\n",
    "    \"\"\"\n",
    "    total_lines = 0\n",
    "    for filename in os.listdir(gt_label_dir):\n",
    "        if filename.endswith(\".txt\"):  # Assuming label files are in .txt format\n",
    "            label_path = os.path.join(gt_label_dir, filename)\n",
    "            \n",
    "            with open(label_path, 'r') as f:\n",
    "                lines = f.readlines()\n",
    "                total_lines += len(lines)              \n",
    "    return total_lines             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_total_bboxes(gt_label_dir):\n",
    "    \"\"\"\n",
    "    This function reads GT label files from the gt_label_dir and counts the total number of bounding boxes\n",
    "    across all label files.\n",
    "    \n",
    "    Parameters:\n",
    "    - gt_label_dir: Path to the directory containing GT label files in YOLOv5 format.\n",
    "    \"\"\"\n",
    "    total_lines = 0\n",
    "    for filename in os.listdir(gt_label_dir):\n",
    "        if filename.endswith(\".txt\"):  # Assuming label files are in .txt format\n",
    "            label_path = os.path.join(gt_label_dir, filename)\n",
    "            \n",
    "            with open(label_path, 'r') as f:\n",
    "                lines = f.readlines()\n",
    "                total_lines += len(lines)              \n",
    "    return total_lines   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_total_files_in_folder(folder_path):\n",
    "    \"\"\"\n",
    "    This function counts the total number of .txt files in a given directory.\n",
    "    \n",
    "    Parameters:\n",
    "    - folder_path: Path to the directory.\n",
    "    \"\"\"\n",
    "    total_files = len([name for name in os.listdir(folder_path) if name.endswith(\".txt\")])\n",
    "    return total_files\n",
    "\n",
    "def verify_pred_labels(test_dir, n=204):\n",
    "    \"\"\"\n",
    "    This function checks each subdirectory within test_dir ending with 'labelsPred' and\n",
    "    returns a list of those directories where the total number of .txt files is less than n.\n",
    "    \n",
    "    Parameters:\n",
    "    - test_dir: Path to the test directory containing subdirectories.\n",
    "    - n: The threshold number of files.\n",
    "    \"\"\"\n",
    "    folders_with_fewer_files = []\n",
    "    for entry in os.listdir(test_dir):\n",
    "        full_path = os.path.join(test_dir, entry)\n",
    "        if os.path.isdir(full_path) and entry.endswith('labelsPred'):\n",
    "            total_files = count_total_files_in_folder(full_path)\n",
    "            if total_files < n:\n",
    "                print(f\"{entry} has {total_files} files\")\n",
    "                folders_with_fewer_files.append(entry)\n",
    "    return folders_with_fewer_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir = '/home/mautushid/Cowsformer/data/4_all/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verify_pred_labels(test_dir, n=204)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_label_dir = \"/home/mautushid/Cowsformer/data/4_all/test/labels\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_total_bboxes(gt_label_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### chat gpt version (wrong)\n",
    "def get_gt_pred_detections(self, gt_img_path, gt_label_path, pred_label_path):\n",
    "        gt_detections = []\n",
    "        pred_detections = []\n",
    "\n",
    "        gt_labels = sorted([f for f in os.listdir(gt_label_path) if f.endswith(\".txt\")], key=lambda x: os.path.getmtime(os.path.join(gt_label_path, x)))\n",
    "        pred_labels = sorted([f for f in os.listdir(pred_label_path) if f.endswith(\".txt\")], key=lambda x: os.path.getmtime(os.path.join(pred_label_path, x)))\n",
    "\n",
    "        gt_images = self.get_images(gt_img_path)\n",
    "        n_samples_gt = len(gt_images)\n",
    "\n",
    "        if len(gt_labels) != len(pred_labels):\n",
    "            print('The number of GT and predicted labels does not match.')\n",
    "            return gt_detections, pred_detections\n",
    "\n",
    "        for i in range(n_samples_gt):\n",
    "            image = PIL.Image.open(gt_images[i])\n",
    "            img_w, img_h = image.size\n",
    "\n",
    "            gt_label_path_full = os.path.join(gt_label_path, gt_labels[i])\n",
    "            pred_label_path_full = os.path.join(pred_label_path, pred_labels[i])\n",
    "\n",
    "            with open(gt_label_path_full, \"r\") as f:\n",
    "                gt_lines = [line.strip() for line in f.readlines()]\n",
    "\n",
    "            with open(pred_label_path_full, \"r\") as f:\n",
    "                pred_lines = [line.strip() for line in f.readlines()]\n",
    "\n",
    "            # Skip if GT label file is empty\n",
    "            if not gt_lines:\n",
    "                #os.remove(gt_label_path_full)  # Remove empty GT label file\n",
    "                #os.remove(pred_label_path_full)  # Remove corresponding predicted label file\n",
    "                continue\n",
    "\n",
    "            # Initialize empty predicted label file with small values\n",
    "            if not pred_lines:\n",
    "                with open(pred_label_path_full, \"w\") as f:\n",
    "                    #f.write(\"0 0.000001 0.000002 0.000003 0.000004 0.0000001\\n\")\n",
    "                    pred_lines = [\"0 0.000001 0.000002 0.000003 0.000004 0.0000001\"]\n",
    "\n",
    "            # Process GT and predicted detections (Assuming `xywh2xyxy` and `sv.Detections` are defined elsewhere)\n",
    "            # This part of the code remains unchanged, but ensure it handles the new pred_lines correctly.\n",
    "\n",
    "            # Your existing logic to process and create `gt_detections` and `pred_detections` goes here\n",
    "\n",
    "        return gt_detections, pred_detections\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (torchconda)",
   "language": "python",
   "name": "torchconda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
